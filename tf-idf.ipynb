{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "{0: 'and', 1: 'document', 2: 'first', 3: 'is', 4: 'one', 5: 'second', 6: 'the', 7: 'third', 8: 'this'}\n"
     ]
    }
   ],
   "source": [
    "set_of_unique_word = set()\n",
    "\n",
    "\n",
    "for sentence in corpus:\n",
    "    sentence = sentence.split(\" \")\n",
    "    for word in sentence:\n",
    "        set_of_unique_word.add(word)\n",
    "      \n",
    "    \n",
    "print(sorted(set_of_unique_word))\n",
    "set_of_unique_word = sorted(set_of_unique_word)\n",
    "unique_word_with_index = {key:value for key, value in enumerate(set_of_unique_word)}\n",
    "\n",
    "print(unique_word_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 4, 'is': 4, 'first': 2, 'document': 3, 'the': 4, 'second': 1, 'third': 1, 'and': 1, 'one': 1}\n",
      "[[0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2], [0.0, 0.3333333333333333, 0.0, 0.16666666666666666, 0.0, 0.16666666666666666, 0.16666666666666666, 0.0, 0.16666666666666666], [0.16666666666666666, 0.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.0, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], [0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]]\n"
     ]
    }
   ],
   "source": [
    "#calculating term frequency\n",
    "\n",
    "unique_word_with_frequency = {}\n",
    "\n",
    "for sentence in corpus:\n",
    "    sentence = sentence.split(\" \")\n",
    "    sentence = set(sentence)\n",
    "    sentence = list(sentence)\n",
    "    for word in sentence:\n",
    "        if word in unique_word_with_frequency:\n",
    "            unique_word_with_frequency[word] += 1\n",
    "        else:\n",
    "            unique_word_with_frequency[word] = 1\n",
    "print(unique_word_with_frequency)\n",
    "\n",
    "term_frequency_list = []\n",
    "frequency_of_word_in_document = {}\n",
    "\n",
    "\n",
    "def get_frequency_of_word(sentence):\n",
    "    word_frequency = {}\n",
    "    sentence = sentence.split(\" \")\n",
    "    count_of_words_in_sentence =  len(sentence)\n",
    "    for word in sentence:\n",
    "        if word in word_frequency:\n",
    "            word_frequency[word] += 1\n",
    "        else:\n",
    "            word_frequency[word] = 1            \n",
    "    return word_frequency, count_of_words_in_sentence\n",
    "\n",
    "\n",
    "term_frequency_word_list = []\n",
    "unique_word_with_index\n",
    "for sentence in corpus:\n",
    "    frequency_of_word_in_document, count_of_terms_in_document = get_frequency_of_word(sentence)\n",
    "    for key, value in unique_word_with_index.items():\n",
    "        if value in frequency_of_word_in_document:\n",
    "            pass\n",
    "        else:\n",
    "            frequency_of_word_in_document[value] = 0\n",
    "        try:\n",
    "            tf_value = (frequency_of_word_in_document[value]/count_of_terms_in_document)\n",
    "            term_frequency_word_list.append(tf_value)\n",
    "        except ZeroDivisionError:\n",
    "            term_frequency_word_list.append(0)\n",
    "    term_frequency_list.append(term_frequency_word_list)\n",
    "    term_frequency_word_list = []\n",
    "print(term_frequency_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "\n",
    "$IDF(t) = 1+\\log_{e}\\frac{1\\text{ }+\\text{ Total  number of documents in collection}} {1+\\text{Number of documents with term t in it}}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "inverse_document_frequency = []\n",
    "\n",
    "for key, value in unique_word_with_index.items():\n",
    "    idf_value = 1+ math.log((1+len(corpus))/(1+unique_word_with_frequency[value]))\n",
    "    inverse_document_frequency.append(idf_value)\n",
    "print(inverse_document_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "tf_idf_list_corpus = []\n",
    "tf_idf_list = []\n",
    "for tf_list in term_frequency_list:\n",
    "    for index in range(len(inverse_document_frequency)):\n",
    "        tf_idf_value = tf_list[index]*inverse_document_frequency[index]\n",
    "        tf_idf_list.append(tf_idf_value)\n",
    "    tf_idf_list_corpus.append(tf_idf_list)\n",
    "    tf_idf_list = []\n",
    "\n",
    "tf_idf_list_corpus = normalize(tf_idf_list_corpus, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "print(tf_idf_list_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
